program: train_mlp.py
method: bayes
metric:
  name: val_top5_acc
  goal: maximize

parameters:
  # --- Model Architecture ---
  hidden_dim:
    values: [512, 1024, 2048]  # MLPs like to be wide
  embed_dim:
    values: [32, 64]
  dropout:
    values: [0.3, 0.5, 0.7]    # High dropout prevents memorization

  # --- Training ---
  lr:
    values: [0.001, 0.0005, 0.0001] # MLPs usually prefer higher LR than GNNs
  batch_size:
    values: [32, 64]           # Larger batches help CLIP/VICReg
  epochs:
    value: 100
  
  # --- Loss Function ---
  loss_type:
    values: ['clip', 'vicreg']
  
  # --- Data Augmentation (Crucial for small data) ---
  aug_mode:
    values: ['mix', 'jitter']
  drop_prob:
    distribution: uniform
    min: 0.1
    max: 0.4
  sparsity:
    values: [0.0, 0.2]         # Test raw vs sparsified